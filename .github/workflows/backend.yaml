name: Backend Tests

on:
  pull_request:
    types: [opened, synchronize, labeled]
    branches:
      - main
    paths:
      - 'sllm/serve/backends/**'

jobs:
    backend_tests:
        runs-on: [self-hosted, nvidia]
        if: contains(github.event.pull_request.labels.*.name, 'ready-for-gpu-testing')
        container:
          image: nvcr.io/nvidia/cuda:12.6.1-cudnn-devel-ubuntu22.04
          options: --gpus all
        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: '3.10'

            # - name: Install dependencies
            #   run: |
            #       apt-get update && apt-get install -y ca-certificates git
            #       python -m pip install --upgrade pip
            #       pip install -r requirements.txt
            #       pip install -r requirements-worker.txt
            #       pip install -r requirements-test.txt]

            # DO NOT install requirements.txt as this will install the release version of ServerlessLLM Store
            - name: Install dependencies
              run: |
                  apt-get update && apt-get install -y ca-certificates git
                  python -m pip install --upgrade pip
                  pip install -r requirements-worker.txt
                  pip install -r requirements-test.txt

            - name: Install ServerlessLLM Store
              run: |
                  cd sllm_store && \
                  rm -rf build && \
                  pip install .

            - name: Reinstall vLLM and apply patch
              run: |
                  VLLM_VERSION=$(pip show vllm | grep Version | awk '{print $2}') && \
                  pip install --force-reinstall --no-deps vllm==$VLLM_VERSION && \
                  cd sllm_store && \
                  ./vllm_patch/patch.sh

            - name: Install ServerlessLLM
              run: |
                  pip install .

            - name: Run tests
              run: |
                  pytest tests/backend_test