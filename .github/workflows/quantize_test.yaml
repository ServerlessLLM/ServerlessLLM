name: Quantization Test

on:
  pull_request:
    types: [opened, synchronize, labeled]
    branches:
      - main
    paths:
      - 'sllm_store/**'

jobs:
  quantize_test_nvidia:
    runs-on: [self-hosted, nvidia]
    if: contains(github.event.pull_request.labels.*.name, 'ready-for-gpu-testing')
    timeout-minutes: 60
    container:
      image: nvcr.io/nvidia/cuda:12.6.1-cudnn-devel-ubuntu22.04
      options: --gpus all
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          apt-get update && apt-get install -y ca-certificates git
          python -m pip install --upgrade pip
          pip install -r requirements-test.txt

      # Python Tests
      - name: Install ServerlessLLM
        run: |
          cd sllm_store && pip install .

      - name: Start sllm-store Server
        run: |
          export MODEL_FOLDER="./models"
          mkdir -p $MODEL_FOLDER
          nohup sllm-store start --storage-path $MODEL_FOLDER --mem-pool-size 16GB > server.log 2>&1 &
          sleep 10

      - name: Run Python Tests
        timeout-minutes: 30
        run: |
          export MODEL_FOLDER="./models"
          pytest tests/quantize_test

  quantize_test_amd: 
    runs-on: [self-hosted, amd]
    if: contains(github.event.pull_request.labels.*.name, 'ready-for-gpu-testing')
    timeout-minutes: 60
    container:
      image: rocm/pytorch:rocm6.2_ubuntu22.04_py3.10_pytorch_release_2.3.0
      options: --device=/dev/kfd --device=/dev/dri --group-add=video
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
          apt-get update && apt-get install -y ca-certificates git
          python -m pip install --upgrade pip
          pip install -r requirements-test.txt

      - name: Set up using existing torch
        working-directory: sllm_store
        run: |
          python using_existing_torch.py

      - name: Install ServerlessLLM
        env:
          PYTORCH_ROCM_ARCH: "gfx906 gfx908 gfx90a gfx940 gfx941 gfx942 gfx1030 gfx1100"
        run: |
          cd sllm_store && pip install .

      - name: Start sllm-store Server
        run: |
          export MODEL_FOLDER="./models"
          mkdir -p $MODEL_FOLDER
          nohup sllm-store start --storage-path $MODEL_FOLDER --mem-pool-size 16GB > server.log 2>&1 &
          sleep 10

      - name: Run Python Tests
        timeout-minutes: 30
        run: |
          export MODEL_FOLDER="./models"
          export HIP_VISIBLE_DEVICES=0
          pytest tests/quantize_test
