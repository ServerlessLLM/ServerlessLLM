name:

on:
  pull_request:
    types: [opened, synchronize, labeled]
    branches:
      - main
    paths:
      - 'sllm_store/**'


jobs:
  sllm_store_rocm_tests:
    runs-on: [self-hosted, amd]
    if: contains(github.event.pull_request.labels.*.name, 'ready-for-gpu-testing')
    container:
      image: rocm/pytorch:rocm6.2_ubuntu22.04_py3.10_pytorch_release_2.3.0
      options: --device /dev/kfd --device /dev/dri --security-opt seccomp=unconfined
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install dependencies
        run: |
            apt-get update && apt-get install -y ca-certificates git wget bzip2
            python -m pip install --upgrade pip
            pip install -r requirements-test.txt

      - name: Build wheel
        working-directory: sllm_store
        shell: bash
        env:
          PYTORCH_ROCM_ARCH: "gfx906 gfx908 gfx90a gfx940 gfx941 gfx942 gfx1030 gfx1100"
        run: |
            pip install -r requirements-build-rocm.txt
            python setup.py sdist bdist_wheel

      - name: Install ServerlessLLM
        working-directory: sllm_store
        run: |
            grep -v "torch" requirements.txt > requirements-rocm.txt
            pip install -r requirements-rocm.txt
            pip install --no-deps dist/*.whl

      - name: Run Python tests
        working-directory: sllm_store/tests/python
        # Only run transformer tests
        run: |
            pytest test_save_model.py

      - name: Build C++ Project
        working-directory: sllm_store
        shell: bash
        env:
          PYTORCH_ROCM_ARCH: "gfx906 gfx908 gfx90a gfx940 gfx941 gfx942 gfx1030 gfx1100"
        run: |
            bash cpp_build.sh

      - name: Run C++ tests
        working-directory: sllm_store/build
        run: |
            ctest --output-on-failure
