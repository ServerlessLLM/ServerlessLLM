{
    "model": "facebook/opt-2.7b",
    "backend": "transformers",
    "num_gpus": 1,
    "auto_scaling_config": {
        "metric": "concurrency",
        "target": 1,
        "min_instances": 0,
        "max_instances": 10
    },
    "placement_config": {
        "target_nodes": ["0"]
    },
    "backend_config": {
        "pretrained_model_name_or_path": "facebook/opt-2.7b",
        "device_map": "auto",
        "torch_dtype": "float16"
    }
}
