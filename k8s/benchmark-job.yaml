apiVersion: batch/v1
kind: Job
metadata:
  name: sllm-benchmark
  labels:
    kueue.x-k8s.io/queue-name: <YOUR_NAMESPACE>-user-queue  # REQUIRED: Replace with your namespace
spec:
  template:
    metadata:
      labels:
        app: sllm-benchmark
    spec:
      restartPolicy: Never

      containers:
      - name: benchmark
        # Use official ServerlessLLM image
        image: serverlessllm/sllm:latest  # Or use your custom-built image: <YOUR_REGISTRY>/sllm-store:latest

        # Override command to run benchmark
        command: ["/bin/bash", "/scripts/run-benchmark.sh"]

        # Environment configuration
        envFrom:
        - configMapRef:
            name: benchmark-config

        # Additional env vars (override ConfigMap if needed)
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        # Uncomment to override model:
        # - name: MODEL_NAME
        #   value: "facebook/opt-6.7b"
        # - name: NUM_REPLICAS
        #   value: "20"

        # Resource requests (REQUIRED by EIDF)
        resources:
          requests:
            cpu: "<CPU_REQUEST>"           # REQUIRED: e.g., "8"
            memory: "<MEMORY_REQUEST>"     # REQUIRED: e.g., "32Gi"
            nvidia.com/gpu: <GPU_COUNT>    # REQUIRED: e.g., 1
          limits:
            cpu: "<CPU_LIMIT>"             # REQUIRED: e.g., "8"
            memory: "<MEMORY_LIMIT>"       # REQUIRED: e.g., "32Gi"
            nvidia.com/gpu: <GPU_COUNT>    # REQUIRED: e.g., 1

        # Volume mounts
        volumeMounts:
        - name: benchmark-scripts
          mountPath: /scripts
          readOnly: true
        - name: model-storage
          mountPath: /models
        - name: results
          mountPath: /results
        # Optional: NVMe detection
        - name: debug-logs
          mountPath: /debug

      # Volumes
      volumes:
      # Benchmark scripts from repository
      - name: benchmark-scripts
        hostPath:
          path: /path/to/ServerlessLLM/benchmarks  # REQUIRED: Update to actual path
          type: Directory

      # Model storage (NVMe recommended)
      - name: model-storage
        hostPath:
          path: <NVME_MOUNT_PATH>/sllm-models  # REQUIRED: e.g., "/mnt/nvme/sllm-models"
          type: DirectoryOrCreate

      # Results storage
      - name: results
        hostPath:
          path: <RESULTS_PATH>  # REQUIRED: e.g., "/data/benchmark-results"
          type: DirectoryOrCreate
        # Alternative: Use emptyDir for temporary results
        # emptyDir: {}

      - name: debug-logs
        emptyDir: {}

      # Optional: Node selector for specific GPU
      # nodeSelector:
      #   nvidia.com/gpu.product: '<GPU_PRODUCT_NAME>'

---
# Optional: Separate ConfigMap for benchmark scripts (alternative to hostPath)
# Use this if you want to embed scripts directly in K8s instead of using hostPath
apiVersion: v1
kind: ConfigMap
metadata:
  name: benchmark-scripts-embedded
  namespace: <YOUR_NAMESPACE>
data:
  # Note: For production, use hostPath or git-sync instead of embedding
  # This is just a placeholder showing the structure
  run-benchmark.sh: |
    #!/bin/bash
    echo "Use hostPath mount or copy actual script content here"
  generate_report.py: |
    #!/usr/bin/env python3
    # Copy actual script content here if using embedded approach
